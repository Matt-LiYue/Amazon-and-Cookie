\section{Privacy Information Exposure}
Other than the general user behavior regarding to online shopping, we would also like to explore privacy information exposure in Amazon wishlists. it has been shown that many users put their location, birth month and day in their wishlist profiles. We now investigate more such privacy threats. As introduced before, a user is able to write a list-description for each of his/her wishlist in plaintext. Beside the designated purpose of describing the list, users also put much privacy information in these list-descriptions inadvertently or purposefully. For example, in list-descriptions users may mention their relatives' names, education, age, hobbies, etc even though these information has no relation to their wishlists. We believe list-descriptions are a relative source of user information. It is meaningless for a user to lie in list-descriptions since it would not bring any obvious benefit. For privacy concern users, they can simply leave the description empty instead of putting wrong information. Therefore we assume all users are telling the truth in their list-descriptions. By studying to what extent users expose their privacy information, we gain understanding on how users can lose information in their online shopping profiles.

\subsection{List-Descriptions}
As list-descriptions are plaintexts keyed-in by the owners. Averagely a list-description consists of 11.9 words (after removing punctuations). However, the median number of words in a description is only 6, which means that while few users put a long speech in their list-descriptions, users are more likely to write down merely a short sentence. Using Stanford Part-of-Speech (POS) tagger \cite{toutanova2003feature}, we found that approximately 40\% of the words are nouns. High ratio of nouns is able to provide more information regarding to the users. Some of the most frequent meaningful nouns and their percentage in all words are listed in Table~\ref{tb:words}. 

\begin{table}[t]
\centering
\caption{Frequent meaningful nouns in list-descriptions}
\label{tb:words}
\begin{adjustbox}{max width=.5\textwidth}
\begin{tabular}{lcl}
Word & Occurrence in list-descriptions & Percentage \\ \hline
university & 959 & 3.19\%	\\
books & 878 & 2.92\%		\\
music & 704 & 2.34\%		\\
school & 604 & 2.00\%	\\
movies & 363 & 1.21\%	

\end{tabular}
\end{adjustbox}
\end{table}

We can see that people did put personal information in their wishlists. A representative example is the education background (3.19\% users mention ``universities" and 2.00\% users mentioned ``school" in list-descriptions). However, these discreet words cannot generalize the types of personal information users tend to put in their wishlists. If we would like to summarize to what extend do users put their education information in list-descriptions, we need to abstract all hyponyms of the word ``education", which may include ``University", ``College", ``School", ``graduate", etc. Toward this end, we use Wordnet[] to abstract the ISA relations in words of list-descriptions. Wordnet[] is a directed graph database that connects English words with relations. Synsets relation connect words with similar semantic senses. Super-subordinate relations connect words with their hypernyms and hyponyms. Using Wordnet we are able to group related words into more general words. There is another work that uses similar approach to extract semantic pattern from passwords \cite{veras2014semantic}. However, unlike \cite{veras2014semantic} which leverages tree cut model \cite{li1998generalizing} to balance size of the cut and abstraction level, we are particularly interested in certain levels of abstractions which is very hard to automate. For example, we may desire ``relative" more than ``person" or ``sister "in our word abstraction since ``person" is too general while ``sister" is too specific. In order to generalize words in list-descriptions in a proper level, we manually selected 8 representative word abstractions to show how much personal information users exposed in list-descriptions. A word is generalized as following. First, we find all synonyms of the word. Then, for each of the synonyms, we find its hypernyms to up to 5 levels. We do not find all its hypernyms because very high level word is usually too general (such as people, entity, etc.). Besides, we also keep the semantic sense close to the target word by restraining levels. Now we have a word pool where each word inside is related to the target word in a similar or more general level. Finally we search the abstraction word we selected in the word pool. If a match is found, we know the word is related to the abstraction. Note that to ensure higher accuracy, we apply such abstraction on nouns only since other words such as verbs carry little information and the generalization of such words may drift the semantic meaning too far away. 

\begin{table}[t]
\centering
\caption{Personal Information Exposure.}
\label{tb:abstract}
\begin{adjustbox}{max width=.5\textwidth}
\begin{threeparttable}
\begin{tabular}{lcl}
Abstraction & Occurrence in list-descriptions & Percentage \\ \hline
educational\_institution.n.01 & 2545 & 8.47\%	\\
professional.n.01 & 1371 & 4.56\%		\\
relative.n.01 & 2880 & 9.58 \%		\\
spouse.n.01 & 787 & 2.6\%	\\
activity.n.01 & 9822 & 32.68\%	\\
sport.n.01 & 1289 & 4.29\%	\\
social\_group.n.01 & 7240 & 24.09\% 
\end{tabular}
\begin{tablenotes}
      \small
      \item ``.n.01" appended to the words specifies attributes of the words. ``n" indicates it is used as a noun. ``01" means the first meaning of the word. A word is likely to have different meanings. ``01" usually represents the most commonly used meaning.
    \end{tablenotes}
  \end{threeparttable}
\end{adjustbox}
\end{table}

We show the selected abstraction words as well as their frequencies in Table~\ref{tb:abstract}. Clearly users have publicized much personal information in list-descriptions. Specifically we made the following observations. 

\begin{enumerate}[leftmargin=*]
\item A considerable portion of users expose their activities (32.68\%) and affiliations (24.09\%). In a finer-granular sense of activities, 4.29\% users mention certain sports. We found that users are extensively mentioning what they did and what group they belong to. 
\item 8.47\% users talked about their education background. 4.56\% users put occupations-related information in list-descriptions. With these essential information, to re-construct the user profiles can be much easier. 
\item Generally 9.58\% users talked about their relatives. Besides, 2.6\% users put their spouses in wishlists, indicating their marital status.
\end{enumerate}

\section{Personal Information Identification}
We have discussed user information exposure in Amazon wishlists. Such information exposure is directly attributed to user behaviors. That is to say, no matter inadvertently or not, users choose to publicize these information. One may argue that users are responsible for such privacy information loss. Now we study the potential leakage of privacy information that users did not publicize. Specifically, we conduct a pilot study on how to identify user gender from the products in their wishlists. In Amazon, it is possible that a user's gender is unknown. For example, users may only put a nickname in their wishlists to hide their real names and thus their genders.

As our measurement study shows, male and female has significant difference in their shopping behaviors, which is reflected on product type and price in their wishlists. Equipped with this knowledge, we can see that inferring gender information from user wishlists is possible. To show this point, we adopt Support Vector Machine (SVM) to learn the pattern and predict gender of a newly entered user. 

We obtain the ground truth from user names as the name is a direct indicator of gender. All users in our dataset are collected through a name search. Therefore we can easily distinguish male and female users. However, there are users that are return to both male and female searches. We ignore these users in our experiment since their gender are unclear. We selected 4 user features to train our SVM. They are (1) The fraction of number of products in one category to the total number of products in the 13 categories\footnote{They are \textit{Arts, Crafts \& Sewing, Home Improvement, All Beauty, Grocery \& Gourmet Food, All Electronics, Baby, Pet Supplies, Computers, Office Products, Kitchen \& Dining, Amazon Fashion, Camera \& Photo, Home \& Kitchen}.} that show strong gender implications as mentioned in Section~\ref{differentgender}. (2) Total number of items (3) Average item price (4) Largest item price. To conclude, a 16-dimensional vector is used to describe a user. 


To better illustrate how accurately wishlists imply user gender, we setup 5 experiments, in which we trim training and testing sets differently. In each experiment, we set restrictions on training set and testing set. We randomly select 2,500 qualified males and females and we use 80\% of the males and females as training set and the rest 20\% as testing set. Therefore, our experiments consist of 4000 training users and 1000 testing users, in both sets half of users are males and half of users are females. The results are shown in Table~\ref{tb:svm}. Experiment 1 shows the most general case where no selection is made. The prediction accuracy is 72\% under such case, which means it is helpful in predicting the gender of a user. However, it may not be very accurate since there are many users have very few items in their wishlists who are very hard to identify. We tuned our experiments such as requiring the users to have at least 1 of the 13 categories that have strong gender implications (Experiment 2) or to have a relatively abundant products in their wishlists (Experiment 3). After the tuning, the SVM prediction accuracy is increased slightly to 76\%-78\%. We further select users with abundant products in the 13 gender implying categories in training or testing sets (Experiment 4 and 5). In the 2 experiments, we achieved a fairly good performance with over 80\% accuracy. 


\begin{table}[t]
    \begin{adjustbox}{max width=.5\textwidth}
  \begin{threeparttable}
    \caption{SVM Results.}
    \label{tb:svm}
     \begin{tabular}{llllll}
        Experiment &Train 13 & Train all & Test 13 & Test all & Accuracy \\ \hline
		1&$\ge 0$ & $\ge 0$ & $\ge 0$ & $\ge 0$ & 72\% \\
		2&$\ge 0$ & $\ge 1$ & $\ge 0$ & $\ge 1$ & 76\% \\
		3&$\ge 20$ & $\ge 0$ & $\ge 20$ & $\ge 0$ & 78\% \\
		4&$\ge 0$ & $\ge 0$ & $\ge 0$ & $\ge 20$ & 80\% \\
		5&$\ge 0$ & $\ge 20$ & $\ge 0$ & $\ge 20$ & 83\% \\
     \end{tabular}
    \begin{tablenotes}
      \small
      \item The column Train 13 and Test 13 specifies the number of products under the 13 categories that have strongest gender indication in training sets and testing sets. Similarly, the column Train all and Test All specifies the number of products under all categories in training sets and testing sets.
    \end{tablenotes}
  \end{threeparttable}
  \end{adjustbox}
\end{table}


A user may hide his/her name for privacy reason and expect the related personal information (such as gender) is unknown to the public. However, we proved that from solely the products in users' wishlists, we are able to predict such personal information. Especially when users have a relatively large number of products in their wishlists, the gender prediction can be fairly accurate. 







